Tensorflow serving provides a simple and performant method to deploy models with a consistent server architecture and API. This only deploys the model as a standalone service, without functionality to add any additional preprocessing or postprocessing steps, other than those already built into the model. 

Source: https://www.tensorflow.org/tfx/guide/serving

#MLdeployment #tensorflow 